<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>Parallel Programming with MPI For Python - Research Computing in Earth Sciences</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="./parallel-programming-with-mpi-for-python.html">

        <meta name="author" content="Kerry Key" />
        <meta name="keywords" content="mpi,python,parallel programming" />
        <meta name="description" content="MPI For Python" />

        <meta property="og:site_name" content="Research Computing in Earth Sciences" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="Parallel Programming with MPI For Python"/>
        <meta property="og:url" content="./parallel-programming-with-mpi-for-python.html"/>
        <meta property="og:description" content="MPI For Python"/>
        <meta property="article:published_time" content="2017-11-16" />
            <meta property="article:section" content="lectures" />
            <meta property="article:tag" content="mpi" />
            <meta property="article:tag" content="python" />
            <meta property="article:tag" content="parallel programming" />
            <meta property="article:author" content="Kerry Key" />


    <!-- Bootstrap -->
        <link rel="stylesheet" href="./theme/css/bootstrap.lumen.min.css" type="text/css"/>
    <link href="./theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="./theme/css/pygments/default.css" rel="stylesheet">
    <link rel="stylesheet" href="./theme/css/style.css" type="text/css"/>
        <link href="./static/custom.css" rel="stylesheet">





</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="./" class="navbar-brand">
Research Computing in Earth Sciences            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="./pages/schedule.html">
                             Schedule
                          </a></li>
                         <li><a href="./pages/syllabus.html">
                             Syllabus
                          </a></li>
                        <li >
                            <a href="./category/assignments.html">Assignments</a>
                        </li>
                        <li class="active">
                            <a href="./category/lectures.html">Lectures</a>
                        </li>
                        <li >
                            <a href="./category/software.html">Software</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="./parallel-programming-with-mpi-for-python.html"
                       rel="bookmark"
                       title="Permalink to Parallel Programming with MPI For Python">
                        Parallel Programming with MPI For Python
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2017-11-16T00:00:00-05:00"> Thu 16 November 2017</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="./tag/mpi.html">mpi</a>
        /
	<a href="./tag/python.html">python</a>
        /
	<a href="./tag/parallel-programming.html">parallel programming</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <h2>Parallel Computing Overview</h2>
<p>We will start the tutorial with a brief overview on parallel computing concepts:</p>
<p><a href="https://www.dropbox.com/s/2yidkm4e94p0yyj/MPI%20Overview.pdf?dl=0">Overview of Parallel Computing</a></p>
<h2>Installation of mpi4py</h2>
<p>We will be using the MPI for Python package <strong>mpi4py</strong>. If you have a clean <em>geo_scipy</em> environment as described on Ryan's Python installation notes on this website, you should be able to install it without any issues using conda. The first thing to do is to open a terminal shell and activate <em>geo_scipy</em>:</p>
<div class="highlight"><pre><span></span>source activate geo_scipy
</pre></div>


<p>(or you can launch it from the Anaconda app)</p>
<p>Then install <strong>mpi4py</strong>:</p>
<div class="highlight"><pre><span></span>conda install mpi4py
</pre></div>


<h2>What is mpi4py?</h2>
<p>MPI for Python provides MPI bindings for the Python  language, allowing programmers to exploit multiple processor computing systems. mpi4py is  is constructed on top of the MPI-1/2 specifications and provides an object oriented interface which closely follows MPI-2 C++ bindings.</p>
<h2>Documentation for mpi4py</h2>
<p>The documentation for mpi4py can be found here:
<a href="https://mpi4py.scipy.org/">https://mpi4py.scipy.org/</a></p>
<p>However, it is still a work in progress and much of it assumes you are already  familiar with the MPI standard. Therefore, you will  probably also need to  consult the MPI standard documentation:</p>
<p><a href="http://mpi-forum.org/docs/">http://mpi-forum.org/docs/</a></p>
<p>The MPI docs only cover the C and Fortran implementations, but the extension to Python syntax is straightforward and in most cases much simpler than the equivalent C or Fortran statements.</p>
<p>Another useful place to look for help is the API reference for mpi4py:</p>
<p><a href="https://mpi4py.scipy.org/docs/apiref/mpi4py.MPI-module.html">https://mpi4py.scipy.org/docs/apiref/mpi4py.MPI-module.html</a></p>
<p>In particular, the section for Class Comm lists all the methods you can use with a communicator object:</p>
<p><a href="https://mpi4py.scipy.org/docs/apiref/mpi4py.MPI.Comm-class.html">https://mpi4py.scipy.org/docs/apiref/mpi4py.MPI.Comm-class.html</a></p>
<p>## Running Python Scripps with MPI</p>
<p>Python programs that use MPI commands must be run using an MPI interpreter, which is provided with the command <code>mpirun</code>. On some systems this command is instead called <code>mpiexec</code> and mpi4py seems to include both.</p>
<p>Make sure your environment is correct by checking that <code>mpirun</code> is in your anaconda directory for <em>geo_scipy</em> by using the <code>which</code> Unix comamnd:</p>
<div class="highlight"><pre><span></span>$ which mpirun
/anaconda/envs/geo_scipy/bin/mpirun
</pre></div>


<p>You can run a MPI Python script using the <code>mpirun</code> command as follows:</p>
<div class="highlight"><pre><span></span>mpirun -n 4 python script.py
</pre></div>


<p>Here the <code>-n 4</code> tells MPI to use four processes, which is the number of cores I have on my laptop. Then we tell MPI to run the python script named <code>script.py</code>.</p>
<p>If you are running this on a desktop computer, then you should adjust the <code>-n</code> argument to be the number of cores on your system or the maximum number of processes needed for your job, whichever is smaller. Or on a large cluster you would specify the number of cores that your program needs or the maximum number of cores available on the particular cluster.</p>
<h2>Communicators and Ranks</h2>
<p>Our first MPI for python example will simply import MPI from the mpi4py package, create a <em>communicator</em> and get the <em>rank</em> of each process:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;My rank is &#39;</span><span class="p">,</span><span class="n">rank</span><span class="p">)</span>
</pre></div>


<p>Save this to a file call <code>comm.py</code> and then run it:</p>
<div class="highlight"><pre><span></span><span class="n">mpirun</span> <span class="o">-</span><span class="n">n</span> <span class="mi">4</span> <span class="n">python</span> <span class="n">comm</span><span class="o">.</span><span class="n">py</span>
</pre></div>


<p>Here we used the default communicator named <code>MPI.COMM_WORLD</code>, which consists of all the processors. For many MPI codes, this is the main communicator that you will need. However, you can create custom communicators using subsets of the processors in <code>MPI.COMM_WORLD</code>. See the documentation for more info.</p>
<h2>Point-to-Point Communication</h2>
<p>Now we will look at how to pass data from one process to another. Here is a very simple example where we pass a dictionary from process 0 to process 1:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">3.14</span><span class="p">}</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;On process 1, data is &#39;</span><span class="p">,</span><span class="n">data</span><span class="p">)</span>
</pre></div>


<p>Here we sent a dictionary, but you could also send an integer with a similar code:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;On process 1, data is &#39;</span><span class="p">,</span><span class="n">idata</span><span class="p">)</span>
</pre></div>


<p>Note how <code>comm.send</code> and <code>comm.recv</code> have lower case <code>s</code> and <code>r</code>.</p>
<p>Now let's look at a more complex example where we send a numpy array:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># in real code, this section might</span>
    <span class="c1"># read in data parameters from a file</span>
    <span class="n">numData</span> <span class="o">=</span> <span class="mi">10</span>  
    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">numData</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">3.14</span><span class="p">,</span><span class="n">numData</span><span class="p">)</span>  
    <span class="n">comm</span><span class="o">.</span><span class="n">Send</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>

    <span class="n">numData</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Number of data to receive: &#39;</span><span class="p">,</span><span class="n">numData</span><span class="p">)</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">numData</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">)</span>  <span class="c1"># allocate space to receive the array</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">Recv</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;data received: &#39;</span><span class="p">,</span><span class="n">data</span><span class="p">)</span>
</pre></div>


<p>Note how <code>comm.Send</code> and <code>comm.Recv</code> used to send and receive the numpy array have upper case <code>S</code> and <code>R</code>.</p>
<h2>Collective Communication</h2>
<h3>Broadcasting:</h3>
<p>Broadcasting takes a variable and sends an exact copy of it to all processes on a communicator. Here are some examples:</p>
<p>Broadcasting a dictionary:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;key1&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
            <span class="s1">&#39;key2&#39;</span> <span class="p">:</span> <span class="p">(</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="s1">&#39;xyz&#39;</span><span class="p">)}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="bp">None</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">bcast</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Rank: &#39;</span><span class="p">,</span><span class="n">rank</span><span class="p">,</span><span class="s1">&#39;, data: &#39;</span> <span class="p">,</span><span class="n">data</span><span class="p">)</span>
</pre></div>


<p>You can broadcasting a numpy array using the <code>Bcast</code> method (again note the capital <code>B</code>). Here we will modify the point-to-point code from above to instead broadcast the array <code>data</code> to all processes in the communicator (rather than just from process 0 to 1):</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># create a data array on process 0</span>
    <span class="c1"># in real code, this section might</span>
    <span class="c1"># read in data parameters from a file</span>
    <span class="n">numData</span> <span class="o">=</span> <span class="mi">10</span>  
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">3.14</span><span class="p">,</span><span class="n">numData</span><span class="p">)</span>  
<span class="k">else</span><span class="p">:</span>
    <span class="n">numData</span> <span class="o">=</span> <span class="bp">None</span>

<span class="c1"># broadcast numData and allocate array on other ranks:</span>
<span class="n">numData</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">bcast</span><span class="p">(</span><span class="n">numData</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>    
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">numData</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">)</span>  

<span class="n">comm</span><span class="o">.</span><span class="n">Bcast</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># broadcast the array from rank 0 to all others</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Rank: &#39;</span><span class="p">,</span><span class="n">rank</span><span class="p">,</span> <span class="s1">&#39;, data received: &#39;</span><span class="p">,</span><span class="n">data</span><span class="p">)</span>
</pre></div>


<h3>Scattering:</h3>
<p>Scatter takes an array and distributes contiguous sections of it  across the ranks of a communicator. Here's an image from http://mpitutorial.com that illustrates the difference between a broadcast and scatter:
<img alt="broadcast and scatter" src="http://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/broadcastvsscatter.png" title="image from http://mpitutorial.com "></p>
<p>Let's try an example now.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span> <span class="c1"># new: gives number of ranks in comm</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="n">numDataPerRank</span> <span class="o">=</span> <span class="mi">10</span>  
<span class="n">data</span> <span class="o">=</span> <span class="bp">None</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span><span class="o">*</span><span class="n">numDataPerRank</span><span class="p">,</span><span class="n">numDataPerRank</span><span class="o">*</span><span class="n">size</span><span class="p">)</span>
    <span class="c1"># when size=4 (using -n 4), data = [1.0:40.0]</span>

<span class="n">recvbuf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">numDataPerRank</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">)</span> <span class="c1"># allocate space for recvbuf</span>
<span class="n">comm</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">recvbuf</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Rank: &#39;</span><span class="p">,</span><span class="n">rank</span><span class="p">,</span> <span class="s1">&#39;, recvbuf received: &#39;</span><span class="p">,</span><span class="n">recvbuf</span><span class="p">)</span>
</pre></div>


<p>In this example, the rank 0 process created the array <code>data</code>. Since this is just a toy example, we made <code>data</code> be a simple linspace array, but in a research code the data might have been read in from a file, or generated by a previous part of the workflow.  <code>data</code> is then scattered to all the ranks (including rank 0) using <code>comm.Scatter</code>. Note that we first had to initialize (or allocate) the receiving buffer array <code>recvbuf</code>.  </p>
<h2>Gathering:</h2>
<p>The reverse of a <code>scatter</code> is a <code>gather</code>, which takes subsets of an array that are distributed across the ranks, and <em>gathers</em> them back into the full array. Here's an image from http://mpitutorial.com that illustrates this graphically:
<img alt="broadcast and scatter" src="http://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/gather.png" title="image from http://mpitutorial.com "></p>
<p>For an example, here is a code that does the reverse of the scatter example above.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>   

<span class="n">numDataPerRank</span> <span class="o">=</span> <span class="mi">10</span>  
<span class="n">sendbuf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">rank</span><span class="o">*</span><span class="n">numDataPerRank</span><span class="o">+</span><span class="mi">1</span><span class="p">,(</span><span class="n">rank</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">numDataPerRank</span><span class="p">,</span><span class="n">numDataPerRank</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Rank: &#39;</span><span class="p">,</span><span class="n">rank</span><span class="p">,</span> <span class="s1">&#39;, sendbuf: &#39;</span><span class="p">,</span><span class="n">sendbuf</span><span class="p">)</span>

<span class="n">recvbuf</span> <span class="o">=</span> <span class="bp">None</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">recvbuf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">numDataPerRank</span><span class="o">*</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">)</span>  

<span class="n">comm</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">sendbuf</span><span class="p">,</span> <span class="n">recvbuf</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Rank: &#39;</span><span class="p">,</span><span class="n">rank</span><span class="p">,</span> <span class="s1">&#39;, recvbuf received: &#39;</span><span class="p">,</span><span class="n">recvbuf</span><span class="p">)</span>
</pre></div>


<h2>Reduction:</h2>
<p>The MP <code>reduce</code> operation takes values in from an array on each process and reduces them to a single result on the root process. This is essentially like having a somewhat complicated send command from each process to the root process, and then having the root process perform the reduction operation. Thankfully,  MPI <code>reduce</code>  does all this with one concise command.</p>
<p>For numpy arrays, the syntax is</p>
<p>~~~python
comm.Reduce(send_data, recv_data, op=<operation>, root=0)
 ~~~
 where <code>send_data</code> is the data being sent from all the processes on the communicator and <code>recv_data</code> is the array on the root process that will receive all the data. Note that the send and recv arrays have the same size.  All the copies of data in  <code>send_data</code> will be reduced according to the specified <code>&lt;operation&gt;</code>.  A few commonly used operations are:
- MPI_SUM - Sums the elements.
- MPI_PROD - Multiplies all elements.
- MPI_MAX - Returns the maximum element.
- MPI_MIN - Returns the minimum element.</p>
<p>Here's a few more useful images from http://mpi_thttp://mpitutorial.com that illustrate the reduce step  graphically:
<img alt="reduce" src="http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/mpi_reduce_1.png">
<img alt="reduce" src="http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/mpi_reduce_2.png"></p>
<p>And here is a code example:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="c1"># Create some np arrays on each process:</span>
<span class="c1"># For this demo, the arrays have only one</span>
<span class="c1"># entry that is assigned to be the rank of the processor</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span><span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39; Rank: &#39;</span><span class="p">,</span><span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; value = &#39;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

<span class="c1"># initialize the np arrays that will store the results:</span>
<span class="n">value_sum</span>      <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">&#39;d&#39;</span><span class="p">)</span>
<span class="n">value_max</span>      <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="c1"># perform the reductions:</span>
<span class="n">comm</span><span class="o">.</span><span class="n">Reduce</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">value_sum</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">MPI</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">Reduce</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">value_max</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">MPI</span><span class="o">.</span><span class="n">MAX</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39; Rank 0: value_sum =    &#39;</span><span class="p">,</span><span class="n">value_sum</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39; Rank 0: value_max =    &#39;</span><span class="p">,</span><span class="n">value_max</span><span class="p">)</span>
</pre></div>
            </div>
            <!-- /.entry-content -->
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Recent Posts -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Recent Posts</span></h4>
  <ul class="list-group" id="recentposts">
    <li class="list-group-item"><a href="./introduction-to-the-habanero-hpc-cluster.html">Introduction to the Habanero HPC Cluster</a></li>
    <li class="list-group-item"><a href="./parallel-programming-with-mpi-for-python.html">Parallel Programming with MPI For Python</a></li>
    <li class="list-group-item"><a href="./assignment-10-packaging-python-code.html">Assignment #10 - Packaging Python Code</a></li>
    <li class="list-group-item"><a href="./organization-and-packaging-of-python-projects.html">Organization and Packaging of Python Projects</a></li>
    <li class="list-group-item"><a href="./assignment-9-map-making-and-geomapapp.html">Assignment #9 -  Map Making and GeoMapApp</a></li>
    <li class="list-group-item"><a href="./intro-to-basemap.html">Map making in Python with Basemap</a></li>
    <li class="list-group-item"><a href="./final-project-instructions.html">Final Project Instructions</a></li>
    <li class="list-group-item"><a href="./introduction-to-generic-mapping-tools-gmt.html">Introduction to Generic Mapping Tools (GMT)</a></li>
    <li class="list-group-item"><a href="./assignment-8-xarray.html">Assignment 8 - Xarray</a></li>
    <li class="list-group-item"><a href="./xarray.html">Intermediate Python III: Xarray for Multidimensional Data</a></li>
  </ul>
</li>
<!-- End Sidebar/Recent Posts -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="./"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group " id="tags">
    <li class="list-group-item tag-1">
      <a href="./tag/programming.html">programming</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="./tag/shell.html">shell</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="./tag/assignment.html">assignment</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="./tag/unix.html">unix</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="./tag/file-system.html">file system</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="./tag/bash.html">bash</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="./tag/python.html">python</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="./tag/pandas.html">pandas</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="./tag/visualization.html">visualization</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="./tag/git.html">git</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="./tag/fortran.html">fortran</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="./tag/gmt.html">GMT</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="./tag/matlab.html">MATLAB</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/arrays.html">arrays</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/github.html">github</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/xarray.html">xarray</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/version-control.html">version control</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/habanero.html">habanero</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/numpy.html">numpy</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/mapping.html">mapping</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/ndarray.html">ndarray</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/mpi.html">mpi</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/packaging.html">packaging</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/geomapapp.html">GeoMapApp</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/matplotlib.html">matplotlib</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/final.html">final</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/source-code-editor.html">source code editor</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/cluster.html">cluster</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/vpn.html">vpn</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/project.html">project</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/basemap.html">basemap</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/parallel-computing.html">parallel computing</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="./tag/parallel-programming.html">parallel programming</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2017 Ryan Abernathey and Kerry Key
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>                <p><small>  <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/deed.en"><img alt="Creative Commons License" style="border-width:0" src="//i.creativecommons.org/l/by-nc/4.0/80x15.png" /></a>
    Content
  licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/deed.en">Creative Commons Attribution-NonCommercial 4.0 International License</a>, except where indicated otherwise.
</small></p>
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="./theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="./theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="./theme/js/respond.min.js"></script>

    <script src="./theme/js/bodypadding.js"></script>


</body>
</html>